{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ThisAfternoon', 'Tonight', 'Friday', 'FridayNight', 'Saturday', 'SaturdayNight', 'Sunday', 'SundayNight', 'Monday']\n",
      "['Rain Likely', 'Rain Likelythen MostlyCloudy', 'Partly Sunny', 'Mostly Cloudy', 'ShowersLikely', 'ChanceShowers', 'ShowersLikely', 'ShowersLikely', 'Partly Sunnythen SlightChanceShowers']\n",
      "['High: 54 °F', 'Low: 42 °F', 'High: 49 °F', 'Low: 45 °F', 'High: 53 °F', 'Low: 53 °F', 'High: 68 °F', 'Low: 43 °F', 'High: 47 °F']\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Get class names from dev tools by hovering over them on the website\n",
    "\n",
    "url = \"http://forecast.weather.gov/MapClick.php?lat=41.8843&lon=-87.6324#.WftcLRNSyRs\"\n",
    "req  = requests.get(url)\n",
    "html = req.content\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "#print(soup.prettify())\n",
    "#^ devtools is better\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#find info for this afternoon:\n",
    "\n",
    "#period = soup.find(class_=\"period-name\") #find only gets the first instance\n",
    "#short_desc = soup.find(class_=\"short-desc\").get_text()\n",
    "#temp = soup.find(class_=\"temp\").get_text()\n",
    "\n",
    "#print(period)\n",
    "#print(short_desc)\n",
    "#print(temp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##################### now we can use lists to get this info for all the time periods\n",
    "\n",
    "period_tags = soup.select(\".period-name\") #select gets all instances and returns a list\n",
    "periods = [pt.get_text() for pt in period_tags]\n",
    "print(periods)\n",
    "short_descs = [sd.get_text() for sd in soup.select(\".short-desc\")] #list comp version\n",
    "print(short_descs)\n",
    "temps = [t.get_text() for t in soup.select(\".temp\")]\n",
    "print(temps)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#then we could put this in a pandas dataframe, write to csv, etc.\n",
    "\n",
    "import pandas as pd\n",
    "weather = pd.DataFrame({\n",
    "        \"period\": periods,\n",
    "        \"short_desc\": short_descs,\n",
    "        \"temp\": temps,\n",
    "    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          period                            short_desc         temp\n",
      "0  ThisAfternoon                           Rain Likely  High: 54 °F\n",
      "1        Tonight          Rain Likelythen MostlyCloudy   Low: 42 °F\n",
      "2         Friday                          Partly Sunny  High: 49 °F\n",
      "3    FridayNight                         Mostly Cloudy   Low: 45 °F\n",
      "4       Saturday                         ShowersLikely  High: 53 °F\n",
      "5  SaturdayNight                         ChanceShowers   Low: 53 °F\n",
      "6         Sunday                         ShowersLikely  High: 68 °F\n",
      "7    SundayNight                         ShowersLikely   Low: 43 °F\n",
      "8         Monday  Partly Sunnythen SlightChanceShowers  High: 47 °F\n"
     ]
    }
   ],
   "source": [
    "print(weather)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "url_va = 'http://historical.elections.virginia.gov/elections/search/year_from:1924/year_to:2015/office_id:1/stage:General'\n",
    "\n",
    "req_va = requests.get(url_va)\n",
    "html_va = req_va.content\n",
    "soup = BeautifulSoup(htmlva, 'html.parser')\n",
    "tags = soup.find_all('tr', 'election_item')\n",
    "lastyear=tags[0]\n",
    "lastyear['id']\n",
    "\n",
    "lastyear.td.text #Will output the date from this dataset.\n",
    "\n",
    "#Assignment requries you do this for all.\n",
    "\n",
    "for t in tags:\n",
    "    year = t.td.text #t is the particular row of data, td is an element of that row, and .text is the content within td\n",
    "    year_id = t['id'][-5:] #-5 shows only the final 5 characters in the output, which are the #s that we want.\n",
    "    print\n",
    "    \n",
    "    \n",
    "base = \"url...{}...\"\n",
    "lastyear_url= base.format('80871')\n",
    "requests.get(lastyear_url).txt\n",
    "\n",
    "with open('2016.csv', 'w') as output:\n",
    "    output.write(requests.get(lastyear_url).text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
